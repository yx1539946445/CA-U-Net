   | Name         | Type             | Params
---------------------------------------------------
0  | resnet       | base_resnet      | 21.3 M
1  | DACBlock     | DACblock         | 7.3 M
2  | RMPBlock     | SPPblock         | 513
3  | decoder4     | DecoderBlock     | 250 K
4  | decoder3     | DecoderBlock     | 62.2 K
5  | decoder2     | DecoderBlock     | 15.7 K
6  | decoder1     | DecoderBlock     | 4.6 K
7  | finaldeconv1 | ConvTranspose2d  | 32.8 K
8  | finalconv2   | Conv2d           | 9.2 K
9  | finalconv3   | Conv2d           | 578
10 | loss_func    | CrossEntropyLoss | 0
---------------------------------------------------
29.0 M    Trainable params
0         Non-trainable params
29.0 M    Total params
115.988   Total estimated model params size (MB)
/home/yx/miniconda3/envs/mat/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/home/yx/miniconda3/envs/mat/lib/python3.9/site-packages/torch/nn/functional.py:2952: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")
/home/yx/miniconda3/envs/mat/lib/python3.9/site-packages/torch/nn/functional.py:3060: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn("Default upsampling behavior when mode={} is changed "
/home/yx/miniconda3/envs/mat/lib/python3.9/site-packages/torch/nn/functional.py:1639: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
Global seed set to 2202
/home/yx/miniconda3/envs/mat/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/home/yx/miniconda3/envs/mat/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:322: UserWarning: The number of training samples (5) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
  rank_zero_warn(
input data information of the runtime error transform:
image statistics:
Type: <class 'numpy.ndarray'>
Shape: (256, 256)
Value range: (-1.5331274271011353, 1.823469638824463)
label statistics:
Type: <class 'numpy.ndarray'>
Shape: (256, 256)
Value range: (0, 1)
gap_map statistics:
Type: <class 'numpy.ndarray'>
Shape: (256, 256)
Value range: (0, 0)
image_meta_dict statistics:
Type: <class 'dict'>
Value: {'format': 'PNG', 'mode': 'L', 'width': 911, 'height': 603, 'spatial_shape': array([911, 603]), 'original_channel_dim': 'no_channel', 'filename_or_obj': '../../data/MicroDataset/images/34.png'}
label_meta_dict statistics:
Type: <class 'dict'>
Value: {'format': 'PNG', 'mode': 'RGB', 'width': 911, 'height': 603, 'spatial_shape': array([911, 603]), 'original_channel_dim': -1, 'filename_or_obj': '../../data/MicroDataset/labels/34.png'}
/home/yx/miniconda3/envs/mat/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:689: UserWarning: ModelCheckpoint(monitor='val_loss') not found in the returned metrics: ['train_loss', 'train_loss_step', 'train_loss_epoch']. HINT: Did you call self.log('val_loss', value) in the LightningModule?
  warning_cache.warn(m)
Traceback (most recent call last):
  File "/home/yx/miniconda3/envs/mat/lib/python3.9/site-packages/monai/transforms/transform.py", line 48, in apply_transform
    return transform(data)
  File "/mnt/c/kust/kust/python_code/python_code/code/experiments/unet/../../asamseg/transforms.py", line 82, in __call__
    mask = myut.instance_to_mask(img_dict['label'])
  File "/mnt/c/kust/kust/python_code/python_code/code/experiments/unet/../../asamseg/utils.py", line 211, in instance_to_mask
    instance = 256 * (256 * instance[:, :, 0] + instance[:, :, 1]) + instance[:, :, 2]
IndexError: too many indices for array: array is 2-dimensional, but 3 were indexed
The above exception was the direct cause of the following exception:
Traceback (most recent call last):
  File "/mnt/c/kust/kust/python_code/python_code/code/experiments/unet/myunet.py", line 146, in <module>
    trainer.fit(model, datamodule=data_module)
  File "/home/yx/miniconda3/envs/mat/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 553, in fit
    self._run(model)
  File "/home/yx/miniconda3/envs/mat/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 918, in _run
    self._dispatch()
  File "/home/yx/miniconda3/envs/mat/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 986, in _dispatch
    self.accelerator.start_training(self)
  File "/home/yx/miniconda3/envs/mat/lib/python3.9/site-packages/pytorch_lightning/accelerators/accelerator.py", line 92, in start_training
    self.training_type_plugin.start_training(trainer)
  File "/home/yx/miniconda3/envs/mat/lib/python3.9/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py", line 161, in start_training
    self._results = trainer.run_stage()
  File "/home/yx/miniconda3/envs/mat/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 996, in run_stage
    return self._run_train()
  File "/home/yx/miniconda3/envs/mat/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1045, in _run_train
    self.fit_loop.run()
  File "/home/yx/miniconda3/envs/mat/lib/python3.9/site-packages/pytorch_lightning/loops/base.py", line 111, in run
    self.advance(*args, **kwargs)
  File "/home/yx/miniconda3/envs/mat/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py", line 200, in advance
    epoch_output = self.epoch_loop.run(train_dataloader)
  File "/home/yx/miniconda3/envs/mat/lib/python3.9/site-packages/pytorch_lightning/loops/base.py", line 111, in run
    self.advance(*args, **kwargs)
  File "/home/yx/miniconda3/envs/mat/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 118, in advance
    _, (batch, is_last) = next(dataloader_iter)
  File "/home/yx/miniconda3/envs/mat/lib/python3.9/site-packages/pytorch_lightning/profiler/base.py", line 104, in profile_iterable
    value = next(iterator)
  File "/home/yx/miniconda3/envs/mat/lib/python3.9/site-packages/pytorch_lightning/trainer/supporters.py", line 625, in prefetch_iterator
    last = next(it)
  File "/home/yx/miniconda3/envs/mat/lib/python3.9/site-packages/pytorch_lightning/trainer/supporters.py", line 546, in __next__
    return self.request_next_batch(self.loader_iters)
  File "/home/yx/miniconda3/envs/mat/lib/python3.9/site-packages/pytorch_lightning/trainer/supporters.py", line 574, in request_next_batch
    return apply_to_collection(loader_iters, Iterator, next_fn)
  File "/home/yx/miniconda3/envs/mat/lib/python3.9/site-packages/pytorch_lightning/utilities/apply_func.py", line 96, in apply_to_collection
    return function(data, *args, **kwargs)
  File "/home/yx/miniconda3/envs/mat/lib/python3.9/site-packages/pytorch_lightning/trainer/supporters.py", line 561, in next_fn
    batch = next(iterator)
  File "/home/yx/miniconda3/envs/mat/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 435, in __next__
    data = self._next_data()
  File "/home/yx/miniconda3/envs/mat/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 475, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/yx/miniconda3/envs/mat/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/yx/miniconda3/envs/mat/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/yx/miniconda3/envs/mat/lib/python3.9/site-packages/monai/data/dataset.py", line 92, in __getitem__
    return self._transform(index)
  File "/home/yx/miniconda3/envs/mat/lib/python3.9/site-packages/monai/data/dataset.py", line 568, in _transform
    data = apply_transform(_transform, data)
  File "/home/yx/miniconda3/envs/mat/lib/python3.9/site-packages/monai/transforms/transform.py", line 71, in apply_transform
    raise RuntimeError(f"applying transform {transform}") from e
RuntimeError: applying transform <asamseg.transforms.ConvertLabelAndGenerateGapV2 object at 0x7f1eb0265550>