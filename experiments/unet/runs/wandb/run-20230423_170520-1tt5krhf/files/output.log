   | Name                     | Type                    | Params
----------------------------------------------------------------------
0  | resnet                   | base_resnet             | 21.8 M
1  | dblock                   | DACblock                | 7.3 M
2  | spp                      | SPPblock                | 513
3  | decoder4                 | DecoderBlock            | 250 K
4  | channelmeanmaxattention1 | ChannelMeanMaxAttention | 262 K
5  | spatialattention1        | SpatialAttention        | 98
6  | decoder3                 | DecoderBlock            | 230 K
7  | channelmeanmaxattention2 | ChannelMeanMaxAttention | 65.9 K
8  | spatialattention2        | SpatialAttention        | 98
9  | decoder2                 | DecoderBlock            | 57.9 K
10 | channelmeanmaxattention3 | ChannelMeanMaxAttention | 16.6 K
11 | spatialattention3        | SpatialAttention        | 98
12 | decoder1                 | DecoderBlock            | 15.7 K
13 | finaldeconv1             | ConvTranspose2d         | 32.8 K
14 | finalconv2               | Conv2d                  | 9.2 K
15 | finalconv3               | Conv2d                  | 578
16 | loss_func                | CrossEntropyLoss        | 0
----------------------------------------------------------------------
30.1 M    Trainable params
0         Non-trainable params
30.1 M    Total params
120.310   Total estimated model params size (MB)
/home/yx/miniconda3/envs/mat/lib/python3.9/site-packages/torch/nn/functional.py:2952: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")
/home/yx/miniconda3/envs/mat/lib/python3.9/site-packages/torch/nn/functional.py:3060: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn("Default upsampling behavior when mode={} is changed "
Traceback (most recent call last):
  File "/mnt/c/kust/kust/python_code/python_code/code/experiments/unet/myunet.py", line 141, in <module>
    trainer.fit(model, datamodule=data_module)
  File "/home/yx/miniconda3/envs/mat/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 458, in fit
    self._run(model)
  File "/home/yx/miniconda3/envs/mat/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 756, in _run
    self.dispatch()
  File "/home/yx/miniconda3/envs/mat/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 797, in dispatch
    self.accelerator.start_training(self)
  File "/home/yx/miniconda3/envs/mat/lib/python3.9/site-packages/pytorch_lightning/accelerators/accelerator.py", line 96, in start_training
    self.training_type_plugin.start_training(trainer)
  File "/home/yx/miniconda3/envs/mat/lib/python3.9/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py", line 144, in start_training
    self._results = trainer.run_stage()
  File "/home/yx/miniconda3/envs/mat/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 807, in run_stage
    return self.run_train()
  File "/home/yx/miniconda3/envs/mat/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 842, in run_train
    self.run_sanity_check(self.lightning_module)
  File "/home/yx/miniconda3/envs/mat/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1107, in run_sanity_check
    self.run_evaluation()
  File "/home/yx/miniconda3/envs/mat/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 962, in run_evaluation
    output = self.evaluation_loop.evaluation_step(batch, batch_idx, dataloader_idx)
  File "/home/yx/miniconda3/envs/mat/lib/python3.9/site-packages/pytorch_lightning/trainer/evaluation_loop.py", line 174, in evaluation_step
    output = self.trainer.accelerator.validation_step(args)
  File "/home/yx/miniconda3/envs/mat/lib/python3.9/site-packages/pytorch_lightning/accelerators/accelerator.py", line 226, in validation_step
    return self.training_type_plugin.validation_step(*args)
  File "/home/yx/miniconda3/envs/mat/lib/python3.9/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py", line 161, in validation_step
    return self.lightning_module.validation_step(*args, **kwargs)
  File "/mnt/c/kust/kust/python_code/python_code/code/experiments/unet/../../asamseg/models/my_tanet.py", line 357, in validation_step
    loss = myut.cal_batch_loss(self, batch, self.loss_func, use_sliding_window=True)
  File "/mnt/c/kust/kust/python_code/python_code/code/experiments/unet/../../asamseg/utils.py", line 129, in cal_batch_loss
    preds = inferer(inputs=images, network=model)
  File "/home/yx/miniconda3/envs/mat/lib/python3.9/site-packages/monai/inferers/inferer.py", line 180, in __call__
    return sliding_window_inference(
  File "/home/yx/miniconda3/envs/mat/lib/python3.9/site-packages/monai/inferers/utils.py", line 130, in sliding_window_inference
    seg_prob = predictor(window_data, *args, **kwargs).to(device)  # batched patch segmentation
  File "/home/yx/miniconda3/envs/mat/lib/python3.9/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/mnt/c/kust/kust/python_code/python_code/code/experiments/unet/../../asamseg/models/my_tanet.py", line 320, in forward
    d4_before = torch.cat([self.decoder4(e4), e3], 1)
RuntimeError: Sizes of tensors must match except in dimension 2. Got 32 and 64 (The offending index is 0)